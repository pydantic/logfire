**Pydantic Logfire** is an observability platform built on OpenTelemetry. This repository contains the Python SDK for Logfire and documentation. The server application for recording and displaying data is closed source.

Key aspects:
- Opinionated wrapper around OpenTelemetry (traces, metrics, logs)
- Extensive integrations with popular Python packages
- SQL-based querying of telemetry data

# Code Quality

Pre-commit automatically runs ruff and pyright, but you can also run `make format/lint/typecheck` to run them explicitly, particularly to check files that haven't been changed.

# Documentation

`uv run mkdocs build --no-strict` to build docs, just to check for errors. Expect lots of warnings, only worry about a non-zero exit code.

# Core Structure

```
logfire/
├── __init__.py              # Public API via DEFAULT_LOGFIRE_INSTANCE
├── _internal/               # Internal implementation
│   ├── main.py              # Logfire and LogfireSpan classes
│   ├── config.py            # LogfireConfig, configuration setup
│   ├── config_params.py     # Environment variable and config file handling
│   ├── tracer.py            # ProxyTracerProvider, tracer wrapping
│   ├── metrics.py           # ProxyMeterProvider, metrics handling
│   ├── exporters/           # OTLP, console, test exporters and processors
│   ├── integrations/        # Framework-specific instrumentation
│   ├── auto_trace/          # AST rewriting for auto-instrumentation
│   └── ...
├── integrations/            # Public integration APIs
└── experimental/            # Experimental features

logfire-api/                 # No-op shim package for libraries
tests/                       # Test suite
docs/                        # MkDocs documentation
```

# Testing

Tests that create spans should follow this pattern:

```python
from inline_snapshot import snapshot
from logfire.testing import TestExporter
import logfire

def test_my_thing(exporter: TestExporter):
    # create spans, e.g:
    with logfire.span("a span"):
        ...

    assert exporter.exported_spans_as_dict(parse_json_attributes=True) == snapshot()
```

Then run `uv run pytest -k test_my_thing --inline-snapshot=fix` to automatically fill in `snapshot()` with a list of dicts and check that the results are sane.
If the output changes, running again will automatically update the snapshot in the code.
`TestExporter` normalizes common things. If some remaining fields are non-deterministic (e.g., IDs, timestamps), use `dirty_equals` matchers, e.g:

```python
from dirty_equals import IsStr
from inline_snapshot import snapshot

assert ... == snapshot({
    'name': 'foo',
    'random_id': IsStr(),
})
```

Use `@pytest.mark.anyio` for async tests.

Some tests are decorated with `@pytest.mark.vcr()` and use `pytest-recording` to record HTTP interactions. Existing VCR cassette files should suffice. When creating a new test like this, run `uv run pytest -k test_my_thing --inline-snapshot=fix --record-mode=rewrite`.

# logfire-api

The `logfire-api` package is a no-op shim that libraries can depend on to avoid hard dependencies on Logfire itself. It provides minimal 'implementations' in `logfire-api/logfire_api/__init__.py`, which needs to be kept up to date with the public API of the `logfire` module, especially if `test_logfire_api.py` starts failing. The rest is just `.pyi` stubs which should be ignored and are autogenerated when needed during release.

# Misc

Use `git push origin HEAD` to push, not just `git push`, so that it pushes to the current branch without needing to set upstream explicitly.

<!-- braindump: rules extracted from PR review patterns -->

# Coding Guidelines

Also see directory-specific guidelines:

- [docs/AGENTS.md](docs/AGENTS.md)
- [tests/AGENTS.md](tests/AGENTS.md)

## Code Style

- Use direct access for guaranteed attributes, `getattr()` with defaults for optional ones — Prevents `AttributeError` on non-recording/disabled objects while keeping code clean when attributes are guaranteed to exist
- Avoid unnecessary abstractions and redundant validations — reduces cognitive overhead and prevents maintenance burden — Simpler, more direct code is easier to understand, debug, and maintain than over-engineered solutions with redundant checks or single-use wrappers.
- Extract duplicated logic into shared utilities — reduces maintenance burden and prevents inconsistent behavior — When the same logic exists in multiple places, bugs get fixed in some locations but not others, and changes require multiple updates across the codebase.
- Log parsed objects over raw strings — structured data improves observability and debuggability — Validated/parsed objects provide richer context for debugging and enable better querying in observability tools compared to serialized strings
- Explicitly serialize non-JSON types in logs (e.g., `Fraction` → `str()`) instead of relying on library defaults — Ensures consistent, human-readable output across different serialization libraries and prevents brittle dependencies on implementation details

## Testing

- Avoid `# pragma: no cover` unless justified (platform-specific, untestable defensive code) — Ensures code quality by maintaining high test coverage and preventing lazy exclusions of testable code from coverage metrics
- Prioritize test coverage for edge cases, transformations, and duplicated logic — prevents regressions in special-case handling — Duplicated code and transformation logic are common sources of bugs when modified; explicit test coverage catches regressions early.
- Remove redundant tests that duplicate coverage without adding value — Reduces maintenance burden and improves test suite clarity by eliminating noise from duplicate test cases

## API Design

- Serialize wrapper types as their primitive value, not `'"value"'` or `int(42)` syntax — Prevents double-encoding bugs and ensures APIs return clean, expected primitives rather than constructor-wrapped representations.
- Return empty collections (`[]`, `{}`) instead of `None` unless `None` has distinct meaning — Avoids null checks in consumer code and prevents `AttributeError`/`TypeError` when callers iterate or call methods on results
- Promote commonly-used params from `**kwargs` to explicit signature parameters — Makes APIs discoverable via autocomplete/type checkers and prevents silent typos in parameter names

## Error Handling

- Check for `None` before using optional values — prevents `AttributeError` and `TypeError` at runtime — Accessing attributes, calling methods, or passing `None` to functions expecting non-null types causes runtime crashes that static typing may not catch.
- Use `.pop()` not `.get()` when extracting `**kwargs` values passed as explicit args — prevents duplicate keyword argument errors — Using `.get()` leaves the key in `**kwargs`, causing `TypeError: got multiple values for keyword argument` when the dict is unpacked.

## Imports

- Place imports at module top level, not inside functions — improves load time, readability, and catches import errors early — Top-level imports are caught at module load time rather than during execution, making failures more predictable and allowing static analysis tools to detect issues.
- Import from top-level package namespace, not internal submodules — ensures backward compatibility and respects public API boundaries — Internal submodules can change without notice; top-level imports guarantee stability and indicate intentional public APIs.

## General

- Remove outdated docs after code changes — stale docs mislead users and waste debugging time — Outdated documentation actively harms users by teaching incorrect patterns and makes maintainers waste time fielding preventable support questions.
- Use conceptual API names (e.g., `chat`) consistently across providers, not endpoint names (e.g., `messages`, `completions`) — Users expect consistent APIs across providers; conceptual naming prevents confusion from implementation-specific endpoint details and makes the codebase easier to navigate.

<!-- /braindump -->